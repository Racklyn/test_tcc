# Scraper - Selenium Web Scraping

M√≥dulo respons√°vel pela extra√ß√£o automatizada de publica√ß√µes e coment√°rios de p√°ginas do Facebook, utilizando Selenium para web scraping e automa√ß√£o de navegador.

## üéØ Sobre o M√≥dulo

O **Scraper** √© um servi√ßo Python que utiliza Selenium WebDriver para:

- **Extrair publica√ß√µes** de p√°ginas do Facebook de marcas cadastradas
- **Coletar coment√°rios** associados a cada publica√ß√£o
- **Navegar automaticamente** pelas p√°ginas do Facebook
- **Armazenar dados** extra√≠dos no banco de dados PostgreSQL
- **Processar datas** e metadados das publica√ß√µes

## üíª Tecnologias

- **Python 3.12**
- **Selenium** - Automa√ß√£o de navegador web
- **FastAPI** - Framework web para APIs
- **Chrome WebDriver** - Driver para automa√ß√£o do Chrome
- **Pandas** - Manipula√ß√£o de dados
- **PostgreSQL** - Banco de dados principal

## üîß Executando o M√≥dulo

### Com Docker (Recomendado)

```bash
# Apenas o banco de dados
docker compose up -d database

# Apenas o servi√ßo de scraping
docker compose up -d scraper
```

### Localmente

#### Pr√©-requisitos
- Python 3.12
- Google Chrome instalado
- ChromeDriver (gerenciado automaticamente pelo webdriver-manager)

#### Configura√ß√£o

1. **Navegue para o diret√≥rio:**
```shell
cd selenium_test/
```

2. **Crie e ative o ambiente virtual:**
```shell
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows
```

3. **Instale as depend√™ncias:**
```shell
pip install -r requirements.txt
```

#### Execu√ß√£o

**Iniciar a API:**
```shell
python api.py
```

**Execu√ß√£o direta do script:**
```shell
# Configure o brand_id e data na fun√ß√£o get_all_pages_and_run() no final do arquivo
python main.py
```

## üìÑ Documenta√ß√£o da API

- **Swagger UI**: http://localhost:5000/docs
- **ReDoc**: http://localhost:5000/redoc

## ‚öôÔ∏è Configura√ß√µes

### Vari√°veis de Ambiente

- `DB_HOST`: Host do banco de dados (padr√£o: database)
- `DB_PORT`: Porta do banco de dados (padr√£o: 5432)
- `DB_USERNAME`: Usu√°rio do banco (padr√£o: postgres)
- `DB_PASSWORD`: Senha do banco (padr√£o: postgres)
- `DB_NAME`: Nome do banco (padr√£o: facebook_brand_analyzer)
- `WEB_SERVICE_URL`: URL do webservice (padr√£o: http://webservice:3000)

### Porta de Execu√ß√£o
- **Desenvolvimento**: 5000
- **Docker**: 5000

## üìù Notas Importantes

- O m√≥dulo utiliza Chrome WebDriver para automa√ß√£o
- √â necess√°rio ter Google Chrome instalado para execu√ß√£o local
- O ChromeDriver √© baixado automaticamente pelo webdriver-manager
- O scraping pode demorar alguns minutos dependendo do volume de dados
- Os dados extra√≠dos s√£o salvos no banco de dados PostgreSQL
- O m√≥dulo depende de marcas e p√°ginas cadastradas no sistema
